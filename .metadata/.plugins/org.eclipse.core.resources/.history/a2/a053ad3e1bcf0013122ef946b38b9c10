package sample;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class KMeansReducer 
extends Reducer<IntWritable,Text,IntWritable,Text> {

	int newCentroid0 = 0;
	int newCentroid1 = 0;
	int newCentroid2 = 0;
	public void reduce(IntWritable key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
     
	//input will be the centroid as key and the user specification as value
	//key = 50; value = uowusers 17 low	
	
	//Average the number of followers for each centroid and emit new centroid
		int totalFollowers = 0;
		int count = 0;
		String[] line;
		for(Text value: values){
			line = value.toString().split(" ");
			totalFollowers += Integer.parseInt(line[1]);
			++count;
		}
		int newCentroid = totalFollowers/count;
		for(Text value: values){
			context.write(new IntWritable(newCentroid), value);
		}
		
		if(newCentroid0 == 0){
			newCentroid0 = newCentroid; 
		}else if(newCentroid1 == 0){
			newCentroid1 = newCentroid;
		}else{
			newCentroid2 = newCentroid;
		}
//		context.write(new IntWritable(newCentroid), value);
	}
	
	@Override
	protected void cleanup(org.apache.hadoop.mapreduce.Reducer.Context context)
			throws IOException, InterruptedException {
		
		super.cleanup(context);
	}
	
}
